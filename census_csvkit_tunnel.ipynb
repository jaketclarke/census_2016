{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Code to import census CSVs to SQL"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "inputpath = 'to_import'\n",
    "outputpath = 'sql'\n",
    "flavour = 'mysql'\n",
    "insertdata = False\n",
    "ssh_address = 'your SSH address'\n",
    "ssh_port = 'your SSH port'\n",
    "# replace these lines with your login details\n",
    "ssh_username = 'your SSH username'\n",
    "ssh_password = 'your SSH password'\n",
    "mysql_username = 'your MySQL username'\n",
    "mysql_password = 'your MySQL password'\n",
    "mysql_database = '2016_census'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Get the CSV Files and make .SQL files from them"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to get csv files to parse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import csvkit\n",
    "import os\n",
    "from os import listdir\n",
    "from os.path import isfile, join"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_files(inputpath):\n",
    "    try:\n",
    "        files = [f for f in listdir(inputpath) if isfile(join(inputpath, f))]\n",
    "        return(files)\n",
    "    except:\n",
    "        print('Couldn\\'t get files for some reason')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Test get_files()\n",
    "inputpath = 'to_import'\n",
    "files = get_files(inputpath)\n",
    "print(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Functions to actually make the schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def make_table_schema(file, inputpath, outputpath, flavour):\n",
    "    try:\n",
    "        # Windows only - get first 10 rows - saves having to infer types from entire file which can be slow\n",
    "        command = 'powershell -command \"& {Get-Content ' + inputpath + '/' + file + ' -TotalCount 10}\" |'\n",
    "        #pick the dialect\n",
    "        command += ' csvsql --dialect ' + flavour + ' --table ' + file[:-4]\n",
    "        # feed output path\n",
    "        command += ' > ' + outputpath + '/' + file[:-4] + '.sql'\n",
    "        \n",
    "        return command\n",
    "    \n",
    "    except:\n",
    "        print('Couldn\\'t make command to build table schema for file: ' + file)\n",
    "\n",
    "def make_table_schemas(files, inputpath = 'to_import', outputpath = 'sql', flavour = 'mysql'):\n",
    "    for file in files:\n",
    "        try:\n",
    "            command = make_table_schema(file, inputpath, outputpath, flavour)\n",
    "            os.system(command)\n",
    "            print('Made schema for: ' + file)\n",
    "        except:\n",
    "            print('Fell over making schema for: ' + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Go! Make the schemas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "make_table_schemas(files)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Execute the .SQL Files"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to get the .SQL file names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sql_files(path = 'sql'):\n",
    "    try:\n",
    "        files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "        return(files)\n",
    "    except:\n",
    "        print('Couldn\\'t get the sql files for some reason')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to get the .SQL file paths"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_sql_file_contents(file, filepath=False):\n",
    "    if filepath:\n",
    "        file = filepath + '/' + file\n",
    "    \n",
    "    try:\n",
    "        fd = open(file, 'r')\n",
    "        sqlFile = fd.read()\n",
    "        fd.close()\n",
    "        return sqlFile\n",
    "    except:\n",
    "        print('Couldn\\'t get the sql file contents for some reason: ' + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to monkey patch the average columns - explained in readme"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def monkey_patch_averages(contents):\n",
    "    contents = contents.replace('`Average_num_psns_per_bedroom` DECIMAL NOT NULL', '`Average_num_psns_per_bedroom` DECIMAL (4,2) NOT NULL')\n",
    "    contents = contents.replace('`Average_household_size` DECIMAL NOT NULL', '`Average_household_size` DECIMAL (4,2) NOT NULL')\n",
    "    return contents"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Actually run it all - Execute the .SQL Files"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "import pymysql\n",
    "import sshtunnel\n",
    "import time\n",
    "sql_files = get_sql_files()\n",
    "\n",
    "with sshtunnel.SSHTunnelForwarder(\n",
    "        (ssh_address, ssh_port),\n",
    "        ssh_username=ssh_username,\n",
    "        ssh_password=ssh_password,\n",
    "        remote_bind_address=(\"127.0.0.1\", 3306)\n",
    ") as tunnel:\n",
    "# sleep to give the tunnel a chance to get established\n",
    "    time.sleep(1)\n",
    "    connection = pymysql.connect(host=\"127.0.0.1\",\n",
    "                                 port=tunnel.local_bind_port,\n",
    "                                 user=mysql_username,\n",
    "                                 password=mysql_password,\n",
    "                                 db=mysql_database,\n",
    "                                 charset='utf8mb4')\n",
    "# loop through sql files\n",
    "    for sql_file in sql_files:\n",
    "      try:\n",
    "        # read them\n",
    "        query = get_sql_file_contents(sql_file, filepath='sql')\n",
    "        query = monkey_patch_averages(query)\n",
    "        cur = connection.cursor()\n",
    "        cur.execute(query)\n",
    "        connection.commit()\n",
    "        print(sql_file + ' done')\n",
    "      except Exception as e:\n",
    "        print(e)\n",
    "    connection.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Write data from the .CSVs into the tables"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to create a mysql connection string to use with Pandas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def create_mysql_engine_string(user,password,host,db,port=3306):\n",
    "    enginestr = 'mysql://'\n",
    "    enginestr += user\n",
    "    enginestr += ':'\n",
    "    enginestr += password\n",
    "    enginestr += '@'\n",
    "    enginestr += host\n",
    "    enginestr += ':'\n",
    "    enginestr += str(port)\n",
    "    enginestr += '/'\n",
    "    enginestr += db\n",
    "    \n",
    "    return enginestr"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Function to take a filename, read it into a Pandas dataframe, and write that dataframe to a mysql table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def insert_into_mysql(file, connection, path=False, flavor = 'mysql'):\n",
    "    \n",
    "    try:\n",
    "        tablename = file[:-4] # strip '.csv'\n",
    "\n",
    "        if path:\n",
    "            file = path + '/' + file\n",
    "        \n",
    "        #header=0 makes it treat the first row as headers\n",
    "        df = pandas.read_csv(file, header=0, sep=',')\n",
    "        \n",
    "        #if_exists = append means insert into\n",
    "        #index=False means don't try to write the Pandas index as a column\n",
    "        df.to_sql(con=connection, name=tablename, if_exists='append', index=False, flavor = flavor)   \n",
    "    except Exception as e:\n",
    "        print(e)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Actually run it - Insert data into the tables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sqlalchemy import create_engine\n",
    "import pandas\n",
    "inputpath = 'to_import'\n",
    "files = get_files(inputpath)\n",
    "\n",
    "\n",
    "with sshtunnel.SSHTunnelForwarder(\n",
    "        (ssh_address, ssh_port),\n",
    "        ssh_username = ssh_username,\n",
    "        ssh_password = ssh_password,\n",
    "        remote_bind_address=(\"127.0.0.1\", 3306)\n",
    ") as tunnel:\n",
    "# sleep to give the tunnel a chance to get established\n",
    "    time.sleep(1)\n",
    "    engine_string = create_mysql_engine_string(mysql_username,mysql_password,\"127.0.0.1\",mysql_database,tunnel.local_bind_port)\n",
    "    engine = create_engine(engine_string)\n",
    "    connection = engine.raw_connection()\n",
    "    # for each .csv, write\n",
    "    for file in files[1:]:\n",
    "        insert_into_mysql(file, connection, path=inputpath)\n",
    "        print('Inserted data for: ' + file)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Add Indexes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def add_index(file):\n",
    "    df = pandas.read_csv(inputpath + '/' + file, header=0, sep=',')\n",
    "    col_name = df.columns[0]\n",
    "    query = \"ALTER TABLE \" + file[:-4] + \" ADD PRIMARY KEY (\" + col_name + \")\"\n",
    "    return query"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "with sshtunnel.SSHTunnelForwarder(\n",
    "        (ssh_address, ssh_port),\n",
    "        ssh_username = ssh_username,\n",
    "        ssh_password = ssh_password,\n",
    "        remote_bind_address=(\"127.0.0.1\", 3306)\n",
    ") as tunnel:\n",
    "# sleep to give the tunnel a chance to get established\n",
    "    time.sleep(1)\n",
    "    connection = pymysql.connect(host=\"127.0.0.1\",\n",
    "                                 port=tunnel.local_bind_port,\n",
    "                                 user=mysql_username,\n",
    "                                 password=mysql_password,\n",
    "                                 db=mysql_database,\n",
    "                                 charset='utf8mb4')\n",
    "# loop through tables\n",
    "    for file in files:\n",
    "      try:\n",
    "        query = add_index(file)\n",
    "        cur = connection.cursor()\n",
    "        cur.execute(query)\n",
    "        connection.commit()\n",
    "        print(file + \" done\")\n",
    "      except Exception as e:\n",
    "        print(e)\n",
    "    connection.close()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
